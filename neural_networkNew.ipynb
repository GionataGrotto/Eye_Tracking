{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GionataGrotto/Eye_Tracking/blob/main/neural_networkNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPcI5nCwrBYk",
        "outputId": "6281dc8a-c7e7-4bb2-c5c3-c84238b7749b"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# from our folder select the right folder containing the dataset\n",
        "root = \"/content/drive/MyDrive/Project_AI/All/\"\n",
        "print(\"inserted root\" + root)\n",
        "\n",
        "#select classifier\n",
        "myCascadeClassifier = cv2.CascadeClassifier(\"/content/drive/MyDrive/Project_AI/haarcascade_eye.xml\")\n",
        "\n",
        "\n",
        "# 1920 x 1080 pixels\n",
        "# When normalize coordindates they will be between 0 and 1\n",
        "#because coordinates goes from 0 to 1919 and from 0 to 1079\n",
        "screenWidth, screenHeight = 1919, 1079 \n",
        "\n",
        "#Python method listdir() returns a list containing the names of the entries in the directory given by path.\n",
        "#The list is in arbitrary order. It does not include the special entries '.' and '..' even if they are present in the directory.\n",
        "listOfPaths = os.listdir(root)\n",
        "\n",
        "\n",
        "#X images\n",
        "#Y labels (coordinate of gaze)\n",
        "X, Y = [], []\n",
        "\n",
        "#read images from inserted path of dataset directory\n",
        "for imagePath in listOfPaths:\n",
        "  #get coordinates from file name\n",
        "  coord_x, coord_y, _ = imagePath.split(' ') #Strings of type \"560 450 Button.left.jpeg\"\n",
        "  \n",
        "  #normalize coordinates ----> from [0:1919; 0:1079] to [0:1; 0:1]\n",
        "  coord_x = float(coord_x) / screenWidth\n",
        "  coord_y = float(coord_y) / screenHeight\n",
        "  \n",
        "  imgRead = cv2.imread(root + imagePath)\n",
        "  \n",
        "  X.append(imgRead)\n",
        "  Y.append([coord_x, coord_y])\n",
        "  \n",
        "#convert to np array\n",
        "X = np.array(X) / 255.0 #normalize colors between 0 and 1\n",
        "Y = np.array(Y)\n",
        "print (\"X.shape, Y.shape: \",X.shape, Y.shape) # (#of images, height, width, #of colors) (#of images, 2)\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y86qyMGzolG"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(2,2), activation='relu', input_shape=(12,44,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  print(\"*****epoca*****\", epoch)\n",
        "  model.fit(X, Y, batch_size = 16)\n",
        "  \n",
        "\n",
        "model.save(\"/content/drive/MyDrive/Project_AI/my_model1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPx_AIFr3YA6",
        "outputId": "66e67855-00bc-4a10-f1c1-48605b5df45d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, 2, activation = 'relu', input_shape = (12, 44, 3)))\n",
        "model.add(Conv2D(64, 2, 2, activation = 'relu'))\n",
        "model.add(keras.layers.Dropout(0.3)),\n",
        "model.add(Conv2D(128, 2, 2, activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(keras.layers.Dense(4096, activation='relu')),\n",
        "model.add(keras.layers.Dropout(0.5)),\n",
        "model.add(keras.layers.Dense(4096, activation='relu')),\n",
        "model.add(keras.layers.Dropout(0.5)),\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  print(\"*****epoca*****\", epoch)\n",
        "  model.fit(X_train, Y_train, batch_size = 16,\n",
        "            validation_data=(X_val,Y_val))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "model.save(\"/content/drive/MyDrive/Project_AI/my_model2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNz4-RYSgJAa",
        "outputId": "d42845b3-f35f-4af0-d54f-c892ee44d48a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, 3, 2, activation = 'relu', input_shape = (12, 44, 3)))\n",
        "model.add(Conv2D(64, 2, 2, activation = 'relu'))\n",
        "keras.layers.MaxPool2D(pool_size=[2,2]),\n",
        "keras.layers.Dropout(0.4),\n",
        "model.add(Conv2D(128, 2, 2, activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "keras.layers.Dense(4096, activation='relu'),\n",
        "keras.layers.Dropout(0.5),\n",
        "keras.layers.Dense(4096, activation='relu'),\n",
        "keras.layers.Dropout(0.5),\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  print(\"*****epoca*****\", epoch)\n",
        "  model.fit(X_train, Y_train, batch_size = 16,\n",
        "            validation_data=(X_val,Y_val))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "model.save(\"/content/drive/MyDrive/Project_AI/my_model3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6JGxoLPAnb1",
        "outputId": "6cbeedd9-1e2a-4584-bbec-40537b12cb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inserted root/content/drive/MyDrive/Project_AI/separati/\n",
            "X.shape, Y.shape:  (1013, 12, 44, 3) (1013, 2)\n"
          ]
        }
      ],
      "source": [
        "# I loaded all the datasets divided in folders and splitted it in train, validation and test\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "root = \"/content/drive/MyDrive/Project_AI/separati/\"\n",
        "print(\"inserted root\" + root)\n",
        "\n",
        "#select classifier\n",
        "myCascadeClassifier = cv2.CascadeClassifier(\"/content/drive/MyDrive/Project_AI/haarcascade_eye.xml\")\n",
        "\n",
        "\n",
        "# 1920 x 1080 pixels\n",
        "# When normalize coordindates they will be between 0 and 1\n",
        "#because coordinates goes from 0 to 1919 and from 0 to 1079\n",
        "screenWidth, screenHeight = 1919, 1079 \n",
        "\n",
        "#Python method listdir() returns a list containing the names of the entries in the directory given by path.\n",
        "#The list is in arbitrary order. It does not include the special entries '.' and '..' even if they are present in the directory.\n",
        "listOfDirs = [name for name in os.listdir(root)]\n",
        "listOfPaths = os.listdir(root)\n",
        "\n",
        "\n",
        "#X images\n",
        "#Y labels (coordinate of gaze)\n",
        "X_train = []\n",
        "X_val = []\n",
        "Y_train = []\n",
        "Y_val = []\n",
        "\n",
        "#read images from inserted path of dataset directory\n",
        "for directory in listOfDirs:\n",
        "  X, Y = [], []\n",
        "  listOfPaths = os.listdir(root+directory+\"/\")\n",
        "  for imagePath in listOfPaths:\n",
        "    #get coordinates from file name\n",
        "    coord_x, coord_y, _ = imagePath.split(' ') #Strings of type \"560 450 Button.left.jpeg\"\n",
        "    \n",
        "    #normalize coordinates ----> from [0:1919; 0:1079] to [0:1; 0:1]\n",
        "    coord_x = float(coord_x) / screenWidth\n",
        "    coord_y = float(coord_y) / screenHeight\n",
        "    \n",
        "    imgRead = cv2.imread(root + directory + \"/\" + imagePath)\n",
        "    \n",
        "    X.append(imgRead)\n",
        "    Y.append([coord_x, coord_y])\n",
        "\n",
        "  X = np.array(X) / 255.0 #normalize colors between 0 and 1\n",
        "  Y = np.array(Y)\n",
        "\n",
        "  tmpX_train, tmpX_val, tmpY_train, tmpY_val = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "\n",
        "  X_train.append(tmpX_train)\n",
        "  X_val.append(tmpX_val)\n",
        "  Y_train.append(tmpY_train)\n",
        "  Y_val.append(tmpY_val)\n",
        "  \n",
        "#convert to np array\n",
        "\n",
        "X_train = np.vstack(X_train)\n",
        "X_val = np.vstack(X_val)\n",
        "Y_train = np.vstack(Y_train)\n",
        "Y_val = np.vstack(Y_val)\n",
        "\n",
        "\n",
        "print (\"X.shape, Y.shape: \",X_train.shape, Y_train.shape) # (#of images, height, width, #of colors) (#of images, 2)\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "   \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX4LbK2fEn8N",
        "outputId": "cb1787bf-36cb-41c7-c5aa-c7acfedc5f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 5, 21, 32)         896       \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 2, 10, 64)         8256      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2, 10, 64)         0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 1, 5, 128)         32896     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4096)              2625536   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,457,090\n",
            "Trainable params: 19,457,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "*****epoca***** 0\n",
            "22/22 [==============================] - 1s 20ms/step - loss: 0.0296 - val_loss: 0.0177\n",
            "*****epoca***** 1\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0149\n",
            "*****epoca***** 2\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0157\n",
            "*****epoca***** 3\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0114\n",
            "*****epoca***** 4\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0093\n",
            "*****epoca***** 5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0064\n",
            "*****epoca***** 6\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.0092\n",
            "*****epoca***** 7\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0073\n",
            "*****epoca***** 8\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0068\n",
            "*****epoca***** 9\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0085\n",
            "*****epoca***** 10\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0080\n",
            "*****epoca***** 11\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0055\n",
            "*****epoca***** 12\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0048\n",
            "*****epoca***** 13\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0053\n",
            "*****epoca***** 14\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0047\n",
            "*****epoca***** 15\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
            "*****epoca***** 16\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0056\n",
            "*****epoca***** 17\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "*****epoca***** 18\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
            "*****epoca***** 19\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "*****epoca***** 20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0038\n",
            "*****epoca***** 21\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0065\n",
            "*****epoca***** 22\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0053\n",
            "*****epoca***** 23\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0044\n",
            "*****epoca***** 24\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0053\n",
            "*****epoca***** 25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0047\n",
            "*****epoca***** 26\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0043\n",
            "*****epoca***** 27\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
            "*****epoca***** 28\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0036\n",
            "*****epoca***** 29\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0045\n",
            "*****epoca***** 30\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0049\n",
            "*****epoca***** 31\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0037\n",
            "*****epoca***** 32\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "*****epoca***** 33\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0035\n",
            "*****epoca***** 34\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "*****epoca***** 35\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0046\n",
            "*****epoca***** 36\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0052\n",
            "*****epoca***** 37\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0038\n",
            "*****epoca***** 38\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0036\n",
            "*****epoca***** 39\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0035\n",
            "*****epoca***** 40\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0035\n",
            "*****epoca***** 41\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0035\n",
            "*****epoca***** 42\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0036\n",
            "*****epoca***** 43\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "*****epoca***** 44\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0044\n",
            "*****epoca***** 45\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0037\n",
            "*****epoca***** 46\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0037\n",
            "*****epoca***** 47\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0032\n",
            "*****epoca***** 48\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "*****epoca***** 49\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0035\n",
            "*****epoca***** 50\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0036\n",
            "*****epoca***** 51\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "*****epoca***** 52\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0036\n",
            "*****epoca***** 53\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "*****epoca***** 54\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0032\n",
            "*****epoca***** 55\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "*****epoca***** 56\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0033\n",
            "*****epoca***** 57\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "*****epoca***** 58\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "*****epoca***** 59\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0042\n",
            "*****epoca***** 60\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0038\n",
            "*****epoca***** 61\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0034\n",
            "*****epoca***** 62\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0035\n",
            "*****epoca***** 63\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0031\n",
            "*****epoca***** 64\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0035\n",
            "*****epoca***** 65\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0030\n",
            "*****epoca***** 66\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0031\n",
            "*****epoca***** 67\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0038\n",
            "*****epoca***** 68\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0033\n",
            "*****epoca***** 69\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0031\n",
            "*****epoca***** 70\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0033\n",
            "*****epoca***** 71\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0040\n",
            "*****epoca***** 72\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "*****epoca***** 73\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "*****epoca***** 74\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0039\n",
            "*****epoca***** 75\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "*****epoca***** 76\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0034\n",
            "*****epoca***** 77\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "*****epoca***** 78\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0031\n",
            "*****epoca***** 79\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0036\n",
            "*****epoca***** 80\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "*****epoca***** 81\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "*****epoca***** 82\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "*****epoca***** 83\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "*****epoca***** 84\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0033\n",
            "*****epoca***** 85\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "*****epoca***** 86\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0033\n",
            "*****epoca***** 87\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "*****epoca***** 88\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0035\n",
            "*****epoca***** 89\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0031\n",
            "*****epoca***** 90\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "*****epoca***** 91\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "*****epoca***** 92\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "*****epoca***** 93\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "*****epoca***** 94\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0031\n",
            "*****epoca***** 95\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0035\n",
            "*****epoca***** 96\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0037\n",
            "*****epoca***** 97\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0030\n",
            "*****epoca***** 98\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "*****epoca***** 99\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "*****epoca***** 100\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0037\n",
            "*****epoca***** 101\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "*****epoca***** 102\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "*****epoca***** 103\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0034\n",
            "*****epoca***** 104\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0031\n",
            "*****epoca***** 105\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0034\n",
            "*****epoca***** 106\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0032\n",
            "*****epoca***** 107\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0035\n",
            "*****epoca***** 108\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "*****epoca***** 109\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0027\n",
            "*****epoca***** 110\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0025\n",
            "*****epoca***** 111\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0029\n",
            "*****epoca***** 112\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0028\n",
            "*****epoca***** 113\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "*****epoca***** 114\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "*****epoca***** 115\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0028\n",
            "*****epoca***** 116\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0029\n",
            "*****epoca***** 117\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "*****epoca***** 118\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "*****epoca***** 119\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "*****epoca***** 120\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "*****epoca***** 121\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0032\n",
            "*****epoca***** 122\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "*****epoca***** 123\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0035\n",
            "*****epoca***** 124\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0032\n",
            "*****epoca***** 125\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "*****epoca***** 126\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "*****epoca***** 127\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0039\n",
            "*****epoca***** 128\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0037\n",
            "*****epoca***** 129\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0034\n",
            "*****epoca***** 130\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0039\n",
            "*****epoca***** 131\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0036\n",
            "*****epoca***** 132\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "*****epoca***** 133\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0038\n",
            "*****epoca***** 134\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "*****epoca***** 135\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "*****epoca***** 136\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0043\n",
            "*****epoca***** 137\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "*****epoca***** 138\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0046\n",
            "*****epoca***** 139\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0027\n",
            "*****epoca***** 140\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "*****epoca***** 141\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0028\n",
            "*****epoca***** 142\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0029\n",
            "*****epoca***** 143\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0032\n",
            "*****epoca***** 144\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0030\n",
            "*****epoca***** 145\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0032\n",
            "*****epoca***** 146\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0031\n",
            "*****epoca***** 147\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "*****epoca***** 148\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0028\n",
            "*****epoca***** 149\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.9060e-04 - val_loss: 0.0029\n",
            "*****epoca***** 150\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0031\n",
            "*****epoca***** 151\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.5152e-04 - val_loss: 0.0034\n",
            "*****epoca***** 152\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.5991e-04 - val_loss: 0.0028\n",
            "*****epoca***** 153\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.0442e-04 - val_loss: 0.0033\n",
            "*****epoca***** 154\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0030\n",
            "*****epoca***** 155\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0034\n",
            "*****epoca***** 156\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.1748e-04 - val_loss: 0.0031\n",
            "*****epoca***** 157\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0039\n",
            "*****epoca***** 158\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "*****epoca***** 159\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "*****epoca***** 160\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0033\n",
            "*****epoca***** 161\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "*****epoca***** 162\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0042\n",
            "*****epoca***** 163\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0034\n",
            "*****epoca***** 164\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0036\n",
            "*****epoca***** 165\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0042\n",
            "*****epoca***** 166\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0028\n",
            "*****epoca***** 167\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.6343e-04 - val_loss: 0.0027\n",
            "*****epoca***** 168\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.4299e-04 - val_loss: 0.0034\n",
            "*****epoca***** 169\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.7941e-04 - val_loss: 0.0029\n",
            "*****epoca***** 170\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0032\n",
            "*****epoca***** 171\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0030\n",
            "*****epoca***** 172\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0031\n",
            "*****epoca***** 173\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0040\n",
            "*****epoca***** 174\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0036\n",
            "*****epoca***** 175\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "*****epoca***** 176\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0038\n",
            "*****epoca***** 177\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0034\n",
            "*****epoca***** 178\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.9656e-04 - val_loss: 0.0031\n",
            "*****epoca***** 179\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0036\n",
            "*****epoca***** 180\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "*****epoca***** 181\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0039\n",
            "*****epoca***** 182\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "*****epoca***** 183\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0040\n",
            "*****epoca***** 184\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0036\n",
            "*****epoca***** 185\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0046\n",
            "*****epoca***** 186\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0037\n",
            "*****epoca***** 187\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.8333e-04 - val_loss: 0.0039\n",
            "*****epoca***** 188\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0032\n",
            "*****epoca***** 189\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.8424e-04 - val_loss: 0.0030\n",
            "*****epoca***** 190\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0035\n",
            "*****epoca***** 191\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0042\n",
            "*****epoca***** 192\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0035\n",
            "*****epoca***** 193\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0043\n",
            "*****epoca***** 194\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0034\n",
            "*****epoca***** 195\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 9.4884e-04 - val_loss: 0.0041\n",
            "*****epoca***** 196\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.3960e-04 - val_loss: 0.0038\n",
            "*****epoca***** 197\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0040\n",
            "*****epoca***** 198\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0035\n",
            "*****epoca***** 199\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 8.2857e-04 - val_loss: 0.0036\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project_AI/my_model2/assets\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, 2, activation = 'relu', input_shape = (12, 44, 3)))\n",
        "model.add(Conv2D(64, 2, 2, activation = 'relu'))\n",
        "model.add(keras.layers.Dropout(0.3)),\n",
        "model.add(Conv2D(128, 2, 2, activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(keras.layers.Dense(4096, activation='relu')),\n",
        "model.add(keras.layers.Dropout(0.5)),\n",
        "model.add(keras.layers.Dense(4096, activation='relu')),\n",
        "model.add(keras.layers.Dropout(0.5)),\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  print(\"*****epoca*****\", epoch)\n",
        "  model.fit(X_train, Y_train, batch_size = 16,\n",
        "            validation_data=(X_val,Y_val))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "model.save(\"/content/drive/MyDrive/Project_AI/my_model2\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOu1KP4GSGPMnxzREZjmhqZ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1bRBIcs5Up14I0ddZXcxZ9--o9_srqx-E",
      "name": "neural_networkNew.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

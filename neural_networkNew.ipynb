{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_networkNew.ipynb",
      "provenance": [],
      "mount_file_id": "1bRBIcs5Up14I0ddZXcxZ9--o9_srqx-E",
      "authorship_tag": "ABX9TyMwnozc9quyLNuX4bbIA9DI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GionataGrotto/Eye_Tracking/blob/main/neural_networkNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgmhwmcZqWFd",
        "outputId": "a2a0078f-af1d-423e-908e-ddcc5c1573e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "'''\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from keras import backend as K\n",
        "'''\n",
        "'''\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "'''\n",
        "'''\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "'''\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#**************************************************************************************************\n",
        "#**************************************************************************************************\n",
        "root = \"/content/drive/MyDrive/Project_AI/All/\"\n",
        "print(\"inserted root\" + root)\n",
        "\n",
        "#select classifier\t  \n",
        "myCascadeClassifier = cv2.CascadeClassifier(\"/content/drive/MyDrive/Project_AI/haarcascade_eye.xml\")\n",
        "\n",
        "\n",
        "#**************************************************************************************************\n",
        "# 1920 x 1080 pixels\n",
        "# When normalize coordindates they will be between 0 and 1\n",
        "#because coordinates goes from 0 to 1919 and from 0 to 1079\n",
        "screenWidth, screenHeight = 1919, 1079 \n",
        "\n",
        "#Python method listdir() returns a list containing the names of the entries in the directory given by path.\n",
        "#The list is in arbitrary order. It does not include the special entries '.' and '..' even if they are present in the directory.\n",
        "listOfPaths = os.listdir(root)\n",
        "\n",
        "\n",
        "#X images\n",
        "#Y labels (coordinate of gaze)\n",
        "X, Y = [], []\n",
        "\n",
        "#read images from inserted path of dataset directory\n",
        "for imagePath in listOfPaths:\n",
        "  #get coordinates from file name\n",
        "  coord_x, coord_y, _ = imagePath.split(' ') #Strings of type \"560 450 Button.left.jpeg\"\n",
        "  \n",
        "  #normalize coordinates ----> from [0:1919; 0:1079] to [0:1; 0:1]\n",
        "  coord_x = float(coord_x) / screenWidth\n",
        "  coord_y = float(coord_y) / screenHeight\n",
        "  \n",
        "  imgRead = cv2.imread(root + imagePath)\n",
        "  \n",
        "  \n",
        "  #togliereeeeeeeeee\n",
        "  #imgRead = cv2.resize(imgRead, (227, 227))\n",
        "  \n",
        "  X.append(imgRead)\n",
        "  Y.append([coord_x, coord_y])\n",
        "  \n",
        "#convert to np array\n",
        "X = np.array(X) / 255.0 #normalize colors between 0 and 1\n",
        "Y = np.array(Y)\n",
        "print (\"X.shape, Y.shape: \",X.shape, Y.shape) # (#of images, height, width, #of colors) (#of images, 2)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "   \n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPcI5nCwrBYk",
        "outputId": "7ae0f9f9-3168-481b-ea3f-3bb2f3d27fd4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inserted root/content/drive/MyDrive/Project_AI/All/\n",
            "X.shape, Y.shape:  (1193, 12, 44, 3) (1193, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(2,2), activation='relu', input_shape=(12,44,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    #keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    #keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  print(\"*****epoca*****\", epoch)\n",
        "  model.fit(X, Y, batch_size = 16)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "model.save(\"/content/drive/MyDrive/Project_AI/my_model1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7y86qyMGzolG",
        "outputId": "d8304746-11a4-4737-e71a-737479d2f86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 5, 21, 96)         2688      \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 5, 21, 96)        384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 5, 21, 256)        614656    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 5, 21, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 5, 21, 384)        885120    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 5, 21, 384)       1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 5, 21, 384)        1327488   \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 5, 21, 384)       1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 5, 21, 256)        884992    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 5, 21, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 2, 10, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 5120)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 4096)              20975616  \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,485,570\n",
            "Trainable params: 41,482,818\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n",
            "*****epoca***** 0\n",
            "75/75 [==============================] - 5s 51ms/step - loss: 0.2713\n",
            "*****epoca***** 1\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 2\n",
            "75/75 [==============================] - 3s 47ms/step - loss: 0.2722\n",
            "*****epoca***** 3\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 4\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 5\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 6\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 7\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 8\n",
            "75/75 [==============================] - 3s 46ms/step - loss: 0.2722\n",
            "*****epoca***** 9\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 10\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 11\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 12\n",
            "75/75 [==============================] - 3s 46ms/step - loss: 0.2722\n",
            "*****epoca***** 13\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 14\n",
            "75/75 [==============================] - 3s 45ms/step - loss: 0.2722\n",
            "*****epoca***** 15\n",
            "71/75 [===========================>..] - ETA: 0s - loss: 0.2707"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c89f05125aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*****epoca*****\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 )\n\u001b[1;32m    546\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, 2, activation = 'relu', input_shape = (12, 44, 3)))\n",
        "model.add(Conv2D(64, 2, 2, activation = 'relu'))\n",
        "keras.layers.MaxPool2D(pool_size=[2,2]),\n",
        "keras.layers.Dropout(0.3),\n",
        "model.add(Conv2D(128, 2, 2, activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "keras.layers.Dense(4096, activation='relu'),\n",
        "keras.layers.Dropout(0.5),\n",
        "keras.layers.Dense(4096, activation='relu'),\n",
        "keras.layers.Dropout(0.5),\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  print(\"*****epoca*****\", epoch)\n",
        "  model.fit(X, Y, batch_size = 16)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "model.save(\"/content/drive/MyDrive/Project_AI/my_model2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPx_AIFr3YA6",
        "outputId": "fa506ed3-bbb1-4ad2-89b1-b295f4c8180f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_57 (Conv2D)          (None, 5, 21, 32)         896       \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 2, 10, 64)         8256      \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 1, 5, 128)         32896     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 2)                 1282      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,330\n",
            "Trainable params: 43,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "*****epoca***** 0\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0501\n",
            "*****epoca***** 1\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0222\n",
            "*****epoca***** 2\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0141\n",
            "*****epoca***** 3\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0114\n",
            "*****epoca***** 4\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0083\n",
            "*****epoca***** 5\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0073\n",
            "*****epoca***** 6\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0063\n",
            "*****epoca***** 7\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0057\n",
            "*****epoca***** 8\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0057\n",
            "*****epoca***** 9\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0051\n",
            "*****epoca***** 10\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0050\n",
            "*****epoca***** 11\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0048\n",
            "*****epoca***** 12\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0045\n",
            "*****epoca***** 13\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0044\n",
            "*****epoca***** 14\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0040\n",
            "*****epoca***** 15\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "*****epoca***** 16\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0041\n",
            "*****epoca***** 17\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0040\n",
            "*****epoca***** 18\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "*****epoca***** 19\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0037\n",
            "*****epoca***** 20\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0035\n",
            "*****epoca***** 21\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0037\n",
            "*****epoca***** 22\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0034\n",
            "*****epoca***** 23\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0034\n",
            "*****epoca***** 24\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0036\n",
            "*****epoca***** 25\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0031\n",
            "*****epoca***** 26\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0034\n",
            "*****epoca***** 27\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0030\n",
            "*****epoca***** 28\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "*****epoca***** 29\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0028\n",
            "*****epoca***** 30\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0029\n",
            "*****epoca***** 31\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "*****epoca***** 32\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0028\n",
            "*****epoca***** 33\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0030\n",
            "*****epoca***** 34\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "*****epoca***** 35\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0027\n",
            "*****epoca***** 36\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "*****epoca***** 37\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0026\n",
            "*****epoca***** 38\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0027\n",
            "*****epoca***** 39\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "*****epoca***** 40\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0023\n",
            "*****epoca***** 41\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "*****epoca***** 42\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "*****epoca***** 43\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0026\n",
            "*****epoca***** 44\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0023\n",
            "*****epoca***** 45\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0024\n",
            "*****epoca***** 46\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0022\n",
            "*****epoca***** 47\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0023\n",
            "*****epoca***** 48\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0024\n",
            "*****epoca***** 49\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0025\n",
            "*****epoca***** 50\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "*****epoca***** 51\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0021\n",
            "*****epoca***** 52\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "*****epoca***** 53\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 54\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0021\n",
            "*****epoca***** 55\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0020\n",
            "*****epoca***** 56\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "*****epoca***** 57\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 58\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0021\n",
            "*****epoca***** 59\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "*****epoca***** 60\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 61\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0018\n",
            "*****epoca***** 62\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0018\n",
            "*****epoca***** 63\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 64\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 65\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "*****epoca***** 66\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0018\n",
            "*****epoca***** 67\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 68\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0016\n",
            "*****epoca***** 69\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0016\n",
            "*****epoca***** 70\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0019\n",
            "*****epoca***** 71\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 72\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0015\n",
            "*****epoca***** 73\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0015\n",
            "*****epoca***** 74\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0015\n",
            "*****epoca***** 75\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 76\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 77\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 78\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 79\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 80\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 81\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 82\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 83\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 84\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0015\n",
            "*****epoca***** 85\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 86\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 87\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 88\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 89\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 90\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 91\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 92\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 93\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 94\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 95\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 96\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 97\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 98\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 99\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0010\n",
            "*****epoca***** 100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 101\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0010\n",
            "*****epoca***** 102\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.3119e-04\n",
            "*****epoca***** 103\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.7287e-04\n",
            "*****epoca***** 104\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 9.8914e-04\n",
            "*****epoca***** 105\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 106\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 107\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.0860e-04\n",
            "*****epoca***** 108\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.3526e-04\n",
            "*****epoca***** 109\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.3100e-04\n",
            "*****epoca***** 110\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.0973e-04\n",
            "*****epoca***** 111\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0010\n",
            "*****epoca***** 112\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 113\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.5623e-04\n",
            "*****epoca***** 114\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.2006e-04\n",
            "*****epoca***** 115\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.9633e-04\n",
            "*****epoca***** 116\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.7079e-04\n",
            "*****epoca***** 117\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 8.1398e-04\n",
            "*****epoca***** 118\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.4358e-04\n",
            "*****epoca***** 119\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.9578e-04\n",
            "*****epoca***** 120\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.0940e-04\n",
            "*****epoca***** 121\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.1592e-04\n",
            "*****epoca***** 122\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.0060e-04\n",
            "*****epoca***** 123\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 7.8347e-04\n",
            "*****epoca***** 124\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.5793e-04\n",
            "*****epoca***** 125\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.5087e-04\n",
            "*****epoca***** 126\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.6865e-04\n",
            "*****epoca***** 127\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 8.2437e-04\n",
            "*****epoca***** 128\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.6282e-04\n",
            "*****epoca***** 129\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.3376e-04\n",
            "*****epoca***** 130\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.6658e-04\n",
            "*****epoca***** 131\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.1997e-04\n",
            "*****epoca***** 132\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.3849e-04\n",
            "*****epoca***** 133\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 6.6055e-04\n",
            "*****epoca***** 134\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.7776e-04\n",
            "*****epoca***** 135\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.4401e-04\n",
            "*****epoca***** 136\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.7659e-04\n",
            "*****epoca***** 137\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.4007e-04\n",
            "*****epoca***** 138\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.0055e-04\n",
            "*****epoca***** 139\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.4421e-04\n",
            "*****epoca***** 140\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 6.0427e-04\n",
            "*****epoca***** 141\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.6900e-04\n",
            "*****epoca***** 142\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.4862e-04\n",
            "*****epoca***** 143\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.4289e-04\n",
            "*****epoca***** 144\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.0035e-04\n",
            "*****epoca***** 145\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.4814e-04\n",
            "*****epoca***** 146\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.0237e-04\n",
            "*****epoca***** 147\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.2239e-04\n",
            "*****epoca***** 148\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.3953e-04\n",
            "*****epoca***** 149\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.8218e-04\n",
            "*****epoca***** 150\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.3423e-04\n",
            "*****epoca***** 151\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.6122e-04\n",
            "*****epoca***** 152\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 5.2458e-04\n",
            "*****epoca***** 153\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.9791e-04\n",
            "*****epoca***** 154\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.1220e-04\n",
            "*****epoca***** 155\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.0885e-04\n",
            "*****epoca***** 156\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.4991e-04\n",
            "*****epoca***** 157\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.6959e-04\n",
            "*****epoca***** 158\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 6.7500e-04\n",
            "*****epoca***** 159\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.0134e-04\n",
            "*****epoca***** 160\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.0604e-04\n",
            "*****epoca***** 161\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.3674e-04\n",
            "*****epoca***** 162\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.7414e-04\n",
            "*****epoca***** 163\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.8410e-04\n",
            "*****epoca***** 164\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.3318e-04\n",
            "*****epoca***** 165\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.3603e-04\n",
            "*****epoca***** 166\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.1603e-04\n",
            "*****epoca***** 167\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.1809e-04\n",
            "*****epoca***** 168\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.3157e-04\n",
            "*****epoca***** 169\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.7870e-04\n",
            "*****epoca***** 170\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.8753e-04\n",
            "*****epoca***** 171\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.7886e-04\n",
            "*****epoca***** 172\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.3581e-04\n",
            "*****epoca***** 173\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.8822e-04\n",
            "*****epoca***** 174\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.0270e-04\n",
            "*****epoca***** 175\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.0482e-04\n",
            "*****epoca***** 176\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.8726e-04\n",
            "*****epoca***** 177\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.0623e-04\n",
            "*****epoca***** 178\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.7559e-04\n",
            "*****epoca***** 179\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.9844e-04\n",
            "*****epoca***** 180\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.5273e-04\n",
            "*****epoca***** 181\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.0949e-04\n",
            "*****epoca***** 182\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 6.0666e-04\n",
            "*****epoca***** 183\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.0324e-04\n",
            "*****epoca***** 184\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.7528e-04\n",
            "*****epoca***** 185\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.7926e-04\n",
            "*****epoca***** 186\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.2957e-04\n",
            "*****epoca***** 187\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.5054e-04\n",
            "*****epoca***** 188\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.8421e-04\n",
            "*****epoca***** 189\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.5288e-04\n",
            "*****epoca***** 190\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.2802e-04\n",
            "*****epoca***** 191\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.3803e-04\n",
            "*****epoca***** 192\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.3297e-04\n",
            "*****epoca***** 193\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.3850e-04\n",
            "*****epoca***** 194\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.4983e-04\n",
            "*****epoca***** 195\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.7711e-04\n",
            "*****epoca***** 196\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.7330e-04\n",
            "*****epoca***** 197\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.0804e-04\n",
            "*****epoca***** 198\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.7815e-04\n",
            "*****epoca***** 199\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.5236e-04\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project_AI/my_model2/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, 3, 2, activation = 'relu', input_shape = (12, 44, 3)))\n",
        "model.add(Conv2D(64, 2, 2, activation = 'relu'))\n",
        "keras.layers.MaxPool2D(pool_size=[2,2]),\n",
        "keras.layers.Dropout(0.4),\n",
        "model.add(Conv2D(128, 2, 2, activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "keras.layers.Dense(4096, activation='relu'),\n",
        "keras.layers.Dropout(0.5),\n",
        "keras.layers.Dense(4096, activation='relu'),\n",
        "keras.layers.Dropout(0.5),\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  print(\"*****epoca*****\", epoch)\n",
        "  model.fit(X, Y, batch_size = 16)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "model.save(\"/content/drive/MyDrive/Project_AI/my_model3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNz4-RYSgJAa",
        "outputId": "2de07a27-b87e-4be1-d5f5-369a5045e922"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 5, 21, 64)         1792      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 2, 10, 64)         16448     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 1, 5, 128)         32896     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 1282      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,418\n",
            "Trainable params: 52,418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "*****epoca***** 0\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0461\n",
            "*****epoca***** 1\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0251\n",
            "*****epoca***** 2\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0156\n",
            "*****epoca***** 3\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0115\n",
            "*****epoca***** 4\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0107\n",
            "*****epoca***** 5\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0085\n",
            "*****epoca***** 6\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0069\n",
            "*****epoca***** 7\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0059\n",
            "*****epoca***** 8\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0054\n",
            "*****epoca***** 9\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0053\n",
            "*****epoca***** 10\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0049\n",
            "*****epoca***** 11\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0048\n",
            "*****epoca***** 12\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0042\n",
            "*****epoca***** 13\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0046\n",
            "*****epoca***** 14\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0039\n",
            "*****epoca***** 15\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0043\n",
            "*****epoca***** 16\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0039\n",
            "*****epoca***** 17\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0039\n",
            "*****epoca***** 18\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0036\n",
            "*****epoca***** 19\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0033\n",
            "*****epoca***** 20\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0033\n",
            "*****epoca***** 21\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0034\n",
            "*****epoca***** 22\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0035\n",
            "*****epoca***** 23\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0034\n",
            "*****epoca***** 24\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0035\n",
            "*****epoca***** 25\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0028\n",
            "*****epoca***** 26\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0030\n",
            "*****epoca***** 27\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0029\n",
            "*****epoca***** 28\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0030\n",
            "*****epoca***** 29\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0026\n",
            "*****epoca***** 30\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0031\n",
            "*****epoca***** 31\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0027\n",
            "*****epoca***** 32\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0025\n",
            "*****epoca***** 33\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0026\n",
            "*****epoca***** 34\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0026\n",
            "*****epoca***** 35\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0024\n",
            "*****epoca***** 36\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0024\n",
            "*****epoca***** 37\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0022\n",
            "*****epoca***** 38\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0024\n",
            "*****epoca***** 39\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0025\n",
            "*****epoca***** 40\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0022\n",
            "*****epoca***** 41\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0023\n",
            "*****epoca***** 42\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0021\n",
            "*****epoca***** 43\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0022\n",
            "*****epoca***** 44\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0020\n",
            "*****epoca***** 45\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0021\n",
            "*****epoca***** 46\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0020\n",
            "*****epoca***** 47\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 48\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0024\n",
            "*****epoca***** 49\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 50\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0018\n",
            "*****epoca***** 51\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0018\n",
            "*****epoca***** 52\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 53\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 54\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0019\n",
            "*****epoca***** 55\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 56\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0020\n",
            "*****epoca***** 57\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 58\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 59\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 60\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 61\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 62\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 63\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0018\n",
            "*****epoca***** 64\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0015\n",
            "*****epoca***** 65\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 66\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 67\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 68\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0016\n",
            "*****epoca***** 69\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 70\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0015\n",
            "*****epoca***** 71\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 72\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 73\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 74\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 75\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0014\n",
            "*****epoca***** 76\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0017\n",
            "*****epoca***** 77\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 78\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 79\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0012\n",
            "*****epoca***** 80\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0013\n",
            "*****epoca***** 81\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 82\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 83\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 84\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 85\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 86\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0011\n",
            "*****epoca***** 87\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0012\n",
            "*****epoca***** 88\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 89\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0012\n",
            "*****epoca***** 90\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0010\n",
            "*****epoca***** 91\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 92\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.9518e-04\n",
            "*****epoca***** 93\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 94\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0010\n",
            "*****epoca***** 95\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.9836e-04\n",
            "*****epoca***** 96\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.7847e-04\n",
            "*****epoca***** 97\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.3992e-04\n",
            "*****epoca***** 98\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.4991e-04\n",
            "*****epoca***** 99\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0011\n",
            "*****epoca***** 101\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.9254e-04\n",
            "*****epoca***** 102\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.0852e-04\n",
            "*****epoca***** 103\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.2410e-04\n",
            "*****epoca***** 104\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 8.7326e-04\n",
            "*****epoca***** 105\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 8.6907e-04\n",
            "*****epoca***** 106\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 9.5853e-04\n",
            "*****epoca***** 107\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0013\n",
            "*****epoca***** 108\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.3170e-04\n",
            "*****epoca***** 109\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0010\n",
            "*****epoca***** 110\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.1900e-04\n",
            "*****epoca***** 111\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.9417e-04\n",
            "*****epoca***** 112\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.1366e-04\n",
            "*****epoca***** 113\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.9944e-04\n",
            "*****epoca***** 114\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.1169e-04\n",
            "*****epoca***** 115\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.2198e-04\n",
            "*****epoca***** 116\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.0725e-04\n",
            "*****epoca***** 117\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0010\n",
            "*****epoca***** 118\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.7700e-04\n",
            "*****epoca***** 119\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.0633e-04\n",
            "*****epoca***** 120\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.4749e-04\n",
            "*****epoca***** 121\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 8.9474e-04\n",
            "*****epoca***** 122\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 9.6946e-04\n",
            "*****epoca***** 123\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.4410e-04\n",
            "*****epoca***** 124\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.9206e-04\n",
            "*****epoca***** 125\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.4472e-04\n",
            "*****epoca***** 126\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.0449e-04\n",
            "*****epoca***** 127\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 7.3188e-04\n",
            "*****epoca***** 128\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.6284e-04\n",
            "*****epoca***** 129\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.2079e-04\n",
            "*****epoca***** 130\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.3802e-04\n",
            "*****epoca***** 131\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.3263e-04\n",
            "*****epoca***** 132\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.5023e-04\n",
            "*****epoca***** 133\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 8.2469e-04\n",
            "*****epoca***** 134\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.1405e-04\n",
            "*****epoca***** 135\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.3470e-04\n",
            "*****epoca***** 136\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.2011e-04\n",
            "*****epoca***** 137\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 8.2365e-04\n",
            "*****epoca***** 138\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.7221e-04\n",
            "*****epoca***** 139\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.5864e-04\n",
            "*****epoca***** 140\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 7.2089e-04\n",
            "*****epoca***** 141\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.7797e-04\n",
            "*****epoca***** 142\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.1559e-04\n",
            "*****epoca***** 143\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.3516e-04\n",
            "*****epoca***** 144\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.6816e-04\n",
            "*****epoca***** 145\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.2460e-04\n",
            "*****epoca***** 146\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.9456e-04\n",
            "*****epoca***** 147\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.3596e-04\n",
            "*****epoca***** 148\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.8845e-04\n",
            "*****epoca***** 149\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.9890e-04\n",
            "*****epoca***** 150\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.9398e-04\n",
            "*****epoca***** 151\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.1757e-04\n",
            "*****epoca***** 152\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.7344e-04\n",
            "*****epoca***** 153\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.9008e-04\n",
            "*****epoca***** 154\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.1336e-04\n",
            "*****epoca***** 155\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.4734e-04\n",
            "*****epoca***** 156\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 7.2815e-04\n",
            "*****epoca***** 157\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.1808e-04\n",
            "*****epoca***** 158\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.2954e-04\n",
            "*****epoca***** 159\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.1278e-04\n",
            "*****epoca***** 160\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.9030e-04\n",
            "*****epoca***** 161\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 7.7064e-04\n",
            "*****epoca***** 162\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.1905e-04\n",
            "*****epoca***** 163\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.6366e-04\n",
            "*****epoca***** 164\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.9667e-04\n",
            "*****epoca***** 165\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.4756e-04\n",
            "*****epoca***** 166\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.0420e-04\n",
            "*****epoca***** 167\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 7.4321e-04\n",
            "*****epoca***** 168\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.1850e-04\n",
            "*****epoca***** 169\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.7529e-04\n",
            "*****epoca***** 170\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 6.0465e-04\n",
            "*****epoca***** 171\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.0155e-04\n",
            "*****epoca***** 172\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.6632e-04\n",
            "*****epoca***** 173\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.6020e-04\n",
            "*****epoca***** 174\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.2658e-04\n",
            "*****epoca***** 175\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.3585e-04\n",
            "*****epoca***** 176\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.7129e-04\n",
            "*****epoca***** 177\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.2743e-04\n",
            "*****epoca***** 178\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 7.4494e-04\n",
            "*****epoca***** 179\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.5393e-04\n",
            "*****epoca***** 180\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.2118e-04\n",
            "*****epoca***** 181\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.1939e-04\n",
            "*****epoca***** 182\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 5.3751e-04\n",
            "*****epoca***** 183\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.4228e-04\n",
            "*****epoca***** 184\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.6022e-04\n",
            "*****epoca***** 185\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 3.8497e-04\n",
            "*****epoca***** 186\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 3.5838e-04\n",
            "*****epoca***** 187\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 3.6930e-04\n",
            "*****epoca***** 188\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 4.1404e-04\n",
            "*****epoca***** 189\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.9890e-04\n",
            "*****epoca***** 190\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.0707e-04\n",
            "*****epoca***** 191\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 3.7729e-04\n",
            "*****epoca***** 192\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.0160e-04\n",
            "*****epoca***** 193\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.9518e-04\n",
            "*****epoca***** 194\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 6.6999e-04\n",
            "*****epoca***** 195\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 5.2195e-04\n",
            "*****epoca***** 196\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.6292e-04\n",
            "*****epoca***** 197\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.4095e-04\n",
            "*****epoca***** 198\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.9232e-04\n",
            "*****epoca***** 199\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 4.5357e-04\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project_AI/my_model3/assets\n"
          ]
        }
      ]
    }
  ]
}